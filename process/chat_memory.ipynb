{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37bc239",
   "metadata": {},
   "source": [
    "# Chat Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b61840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.joiners import ListJoiner\n",
    "from haystack import Pipeline\n",
    "from typing import List\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.converters import OutputAdapter\n",
    "from haystack.utils import Secret\n",
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a83c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Masukkan OpenAI API Key Anda: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf7a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MONGO_CONNECTION_STRING\"] = getpass(\"Masukkan MongoDB Connection String Anda: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110203ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = ChatMessage.from_system(\"You are a helpful assistant that answers questions based on the provided context.\")\n",
    "user_message_template = \"\"\"\n",
    "Answer the question based on the user query:\n",
    "query:{{query}}\n",
    "answer:\n",
    "\"\"\"\n",
    "user_message = ChatMessage.from_user(user_message_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a28836a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x106cca690>\n",
       "ðŸš… Components\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - generator: OpenAIChatGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder.prompt -> generator.messages (List[ChatMessage])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(variables=[\"query\"], required_variables=[\"query\"]))\n",
    "pipeline.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4.1\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))\n",
    "\n",
    "\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0be6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response: AI, or Artificial Intelligence, refers to the ability of machines or computer systems to perform tasks that typically require human intelligence. These tasks can include learning, problem-solving, understanding language, recognizing patterns and images, making decisions, and more. AI systems use algorithms and models to analyze data, adapt to new information, and carry out complex functions automatically.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    messages = [system_message, user_message]\n",
    "    query = input(\"Please input your question or type 'exit' to quit.\\n\")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    res = pipeline.run(\n",
    "        {\n",
    "            \"prompt_builder\": {\n",
    "                \"query\": query,\n",
    "                \"template\":messages\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(\"AI Response:\", res[\"generator\"][\"replies\"][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_store = InMemoryChatMessageStore()\n",
    "memory_retriever = ChatMessageRetriever(memory_store)\n",
    "memory_writer = ChatMessageWriter(memory_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec37672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = ChatMessage.from_system(\"You are a helpful assistant that answers questions based on the provided context.\")\n",
    "user_message_template = \"\"\"\n",
    "Answer the question based on the user query, please pay attention to the chat history:\n",
    "chat_history:\n",
    "{% for memory in memories %}\n",
    "    {{memory.text}}\n",
    "{% endfor %}\n",
    "\n",
    "query:{{query}}\n",
    "answer:\n",
    "\"\"\"\n",
    "user_message = ChatMessage.from_user(user_message_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5354842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x1100b1d90>\n",
       "ðŸš… Components\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - generator: OpenAIChatGenerator\n",
       "  - joiner: ListJoiner\n",
       "  - memory_retriever: ChatMessageRetriever\n",
       "  - memory_writer: ChatMessageWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder.prompt -> generator.messages (List[ChatMessage])\n",
       "  - generator.replies -> joiner.values (List[ChatMessage])\n",
       "  - joiner.values -> memory_writer.messages (List[ChatMessage])\n",
       "  - memory_retriever.messages -> prompt_builder.memories (List[ChatMessage])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(variables=[\"query\",\"memories\"], required_variables=[\"query\",\"memories\"]))\n",
    "pipeline.add_component(\"generator\", OpenAIChatGenerator(model=\"gpt-4.1\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])))\n",
    "pipeline.add_component(\"joiner\", ListJoiner(List[ChatMessage]))\n",
    "pipeline.add_component(\"memory_retriever\", memory_retriever)\n",
    "pipeline.add_component(\"memory_writer\", memory_writer)\n",
    "\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "pipeline.connect(\"generator.replies\", \"joiner\")\n",
    "pipeline.connect(\"joiner\", \"memory_writer\")\n",
    "pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6449283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response: The CEO of Tesla is Elon Musk.\n",
      "AI Response: Elon Musk was born in Pretoria, South Africa.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    messages = [system_message, user_message]\n",
    "    query = input(\"Please input your question or type 'exit' to quit.\\n\")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    res = pipeline.run(\n",
    "        data={\n",
    "            \"prompt_builder\": {\n",
    "                \"query\": query,\n",
    "                \"template\":messages\n",
    "            },\n",
    "            \"joiner\":{\n",
    "                \"values\": [ChatMessage.from_user(query)]\n",
    "            }\n",
    "        },\n",
    "        include_outputs_from=[\"generator\"]\n",
    "    )\n",
    "    # print(res)\n",
    "    print(\"AI Response:\", res[\"generator\"][\"replies\"][0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
