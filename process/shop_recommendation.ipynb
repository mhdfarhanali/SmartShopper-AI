{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5e11ab",
   "metadata": {},
   "source": [
    "# Shop Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7c8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhdfarhanali/Documents/Farhan SmartShopper/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline, component\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.agents import Agent\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.tools.tool import Tool\n",
    "from haystack_experimental.chat_message_stores.in_memory import InMemoryChatMessageStore\n",
    "from haystack_experimental.components.retrievers import ChatMessageRetriever\n",
    "from haystack_experimental.components.writers import ChatMessageWriter\n",
    "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from pymongo import MongoClient\n",
    "from typing import List, Annotated\n",
    "from getpass import getpass\n",
    "import re, json, os, logging\n",
    "from haystack import tracing\n",
    "from haystack.tracing.logging_tracer import LoggingTracer\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n",
    "\n",
    "# Enable tracing for debugging (optional)\n",
    "tracing.tracer.is_content_tracing_enabled = False\n",
    "tracing.enable_tracing(\n",
    "    LoggingTracer(tags_color_strings={\"haystack.component.name\": \"\\x1b[1;34m\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba267cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys & MongoDB credentials\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Masukkan OpenAI API Key Anda: \")\n",
    "os.environ[\"MONGO_CONNECTION_STRING\"] = getpass(\"Masukkan MongoDB Connection String Anda: \")\n",
    "\n",
    "chat_message_store = InMemoryChatMessageStore()\n",
    "\n",
    "document_store = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"products\",\n",
    "    vector_search_index=\"vector_index\",\n",
    "    full_text_search_index=\"search_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2115d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaphraserPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\n",
    "            \"prompt_builder\",\n",
    "            ChatPromptBuilder(variables=[\"query\", \"memories\"], required_variables=[\"query\", \"memories\"]),\n",
    "        )\n",
    "        self.pipeline.add_component(\n",
    "            \"generator\",\n",
    "            OpenAIChatGenerator(model=\"gpt-4.1\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])),\n",
    "        )\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "\n",
    "    def run(self, query):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\"You are a helpful assistant that paraphrases user queries.\"),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                Please paraphrase the query below using previous conversation context if available.\n",
    "                history:\n",
    "                {% for memory in memories %}\n",
    "                    {{memory.text}}\n",
    "                {% endfor %}\n",
    "                query: {{query}}\n",
    "                answer:\n",
    "                \"\"\"\n",
    "            ),\n",
    "        ]\n",
    "        res = self.pipeline.run(\n",
    "            data={\"prompt_builder\": {\"query\": query, \"template\": messages}},\n",
    "            include_outputs_from=[\"generator\"],\n",
    "        )\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b5ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryPipeline:\n",
    "    def __init__(self, chat_message_store):\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"memory_retriever\", ChatMessageRetriever(chat_message_store))\n",
    "        self.pipeline.add_component(\n",
    "            \"prompt_builder\",\n",
    "            PromptBuilder(\n",
    "                variables=[\"memories\"],\n",
    "                required_variables=[\"memories\"],\n",
    "                template=\"\"\"\n",
    "                Previous Conversations:\n",
    "                {% for memory in memories %}\n",
    "                {{memory.text}}\n",
    "                {% endfor %}\n",
    "                \"\"\",\n",
    "            ),\n",
    "        )\n",
    "        self.pipeline.connect(\"memory_retriever\", \"prompt_builder.memories\")\n",
    "\n",
    "    def run(self):\n",
    "        res = self.pipeline.run({}, include_outputs_from=[\"prompt_builder\"])\n",
    "        return res[\"prompt_builder\"][\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "863f769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class GetMaterials:\n",
    "    def __init__(self):\n",
    "        self.client = MongoClient(os.environ[\"MONGO_CONNECTION_STRING\"])\n",
    "        self.db = self.client.depato_store\n",
    "\n",
    "    @component.output_types(materials=List[str])\n",
    "    def run(self):\n",
    "        materials = [doc[\"name\"] for doc in self.db.materials.find()]\n",
    "        return {\"materials\": materials}\n",
    "\n",
    "\n",
    "@component\n",
    "class GetCategories:\n",
    "    def __init__(self):\n",
    "        self.client = MongoClient(os.environ[\"MONGO_CONNECTION_STRING\"])\n",
    "        self.db = self.client.depato_store\n",
    "\n",
    "    @component.output_types(categories=List[str])\n",
    "    def run(self):\n",
    "        categories = [doc[\"name\"] for doc in self.db.categories.find()]\n",
    "        return {\"categories\": categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aefac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FILTER_TEMPLATE = \"\"\"\n",
    "You are a json generator that have a job to generate json based on the input.\n",
    "The return json should be in the format:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\":[\n",
    "        {\"field\": \"meta.category\", \"operator\":\"==\", \"value\": <category>},\n",
    "        {\"field\": \"meta.material\", \"operator\":\"==\", \"value\": <material>},\n",
    "        {\"filed\": \"meta.gender\", \"operator\":\"==\", \"value\" : <male|female|unisex>},\n",
    "        {\"field\": \"meta.price\", \"operator\":<\"<=\"|\">=\"|\"==\">, \"value\": <price>}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "The json key above can be omiitted if the value is not provided in the input, so please make sure to only return the keys that are provided in the input.\n",
    "\n",
    "For the material and category, you can only use the material and category that are provided below:\n",
    "Materials: [ {% for material in materials %} {{ material }} {% if not loop.last %}, {% endif %} {% endfor %} ]\n",
    "\n",
    "Categories: [ {% for category in categories %} {{ category }} {% if not loop.last %}, {% endif %} {% endfor %} ]\n",
    "\n",
    "if the input does not contain any of the keys above, you should return an empty json object like this:\n",
    "```json\n",
    "{}\n",
    "```\n",
    "Sometimes the material and category can be negated, so you should also handle that by using the operator \"!=\" for material and category. \n",
    "\n",
    "Sometimes the material and category is not explicitly mentioned, you should analyze which material and category is the most suitable based on the input, and return the json with the material and category that you think is the most suitable.\n",
    "\n",
    "Nestede conditions are allowed, for nested conditions, you can use \"OR\" and \"AND\" as the operator, and the conditions should be in the \"conditions\" array.\n",
    "\n",
    "if user said the price around some value, please find the price between those value -10 and value +10.\n",
    "\n",
    "The example of the result are expected to be like this:\n",
    "\n",
    "1. Input: \"can you give me a adress with cotton material?\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Cotton\"},\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "2. Input: \"Give me Shirt that is not made of cotton and has a price less than $100\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Tops\"},\n",
    "        {\"field\": \"meta.material\", \"operator\": \"!=\", \"value\": \"Cotton\"},\n",
    "        {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 100}\n",
    "    ]\n",
    "}\n",
    "3. Input: \"I want a dress that is not hot and has a price greater than $50\"\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"},\n",
    "        {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 50},\n",
    "        {\n",
    "            \"operator\": \"OR\",\n",
    "            \"conditions\": [\n",
    "                {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Cotton\"},\n",
    "                {\"field\": \"meta.material\", \"operator\": \"==\", \"value\": \"Polyester\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "4. Input i want tops that have price between $20 and $50\n",
    "output:\n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Tops\"},\n",
    "        {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\":[\n",
    "                {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 20},\n",
    "                {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 50}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "5. Input: I want the dress price around $50\n",
    "output: \n",
    "```json\n",
    "{\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\"field\": \"meta.category\", \"operator\": \"==\", \"value\": \"Dresses/Jumpsuits\"},\n",
    "        {\n",
    "            \"operator\": \"AND\",\n",
    "            \"conditions\":[\n",
    "                {\"field\": \"meta.price\", \"operator\": \">=\", \"value\": 40},\n",
    "                {\"field\": \"meta.price\", \"operator\": \"<=\", \"value\": 60}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "6. Input: {{input}}\n",
    "output:\n",
    "\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a168fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDataFilterPipeline:\n",
    "    def __init__(self, template):\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"materials\", GetMaterials())\n",
    "        self.pipeline.add_component(\"categories\", GetCategories())\n",
    "        self.pipeline.add_component(\n",
    "            \"prompt_builder\",\n",
    "            PromptBuilder(template=template, required_variables=[\"input\", \"materials\", \"categories\"]),\n",
    "        )\n",
    "        self.pipeline.add_component(\n",
    "            \"generator\",\n",
    "            OpenAIGenerator(model=\"gpt-4.1\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])),\n",
    "        )\n",
    "\n",
    "        self.pipeline.connect(\"materials.materials\", \"prompt_builder.materials\")\n",
    "        self.pipeline.connect(\"categories.categories\", \"prompt_builder.categories\")\n",
    "        self.pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "\n",
    "    def run(self, query: str):\n",
    "        res = self.pipeline.run({\"prompt_builder\": {\"input\": query}}, include_outputs_from=[\"generator\"])\n",
    "        return res[\"generator\"][\"replies\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10512970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieveAndGenerateAnswerPipeline:\n",
    "    def __init__(self, document_store):\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(\"embedder\",SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "        self.pipeline.add_component(\"retriever\", MongoDBAtlasEmbeddingRetriever(document_store=document_store, top_k=10))\n",
    "        self.pipeline.add_component(\n",
    "            \"prompt_builder\",\n",
    "            ChatPromptBuilder(variables=[\"query\", \"documents\"], required_variables=[\"query\", \"documents\"]),\n",
    "        )\n",
    "        self.pipeline.add_component(\n",
    "            \"generator\",\n",
    "            OpenAIChatGenerator(model=\"gpt-4.1\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])),\n",
    "        )\n",
    "        self.pipeline.connect(\"embedder\", \"retriever\")\n",
    "        self.pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "        self.pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\")\n",
    "\n",
    "    def run(self, query: str, filter: dict = {}):\n",
    "        messages = [\n",
    "            ChatMessage.from_system(\"You are a shop assistant that recommends products.\"),\n",
    "            ChatMessage.from_user(\n",
    "                \"\"\"\n",
    "                The query is: {{query}}\n",
    "                {% if documents|length > 0 %}\n",
    "                Products:\n",
    "                {% for product in documents %}\n",
    "                {{loop.index}}. {{product.meta.title}} — ${{product.meta.price}} | {{product.meta.material}} | {{product.meta.category}}\n",
    "                {% endfor %}\n",
    "                {% else %}\n",
    "                No matching products.\n",
    "                {% endif %}\n",
    "                Answer:\n",
    "                \"\"\"\n",
    "            ),\n",
    "        ]\n",
    "        res = self.pipeline.run(\n",
    "            {\n",
    "                \"embedder\": {\"text\": query},\n",
    "                \"retriever\": {\"filters\": filter},\n",
    "                \"prompt_builder\": {\"query\": query, \"template\": messages},\n",
    "            },\n",
    "            include_outputs_from=[\"generator\"],\n",
    "        )\n",
    "        return res[\"generator\"][\"replies\"][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05032c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipelines\n",
    "paraphraser = ParaphraserPipeline(chat_message_store)\n",
    "history = ChatHistoryPipeline(chat_message_store)\n",
    "filter_pipeline = MetaDataFilterPipeline(template=METADATA_FILTER_TEMPLATE)\n",
    "rag_pipeline = RetrieveAndGenerateAnswerPipeline(document_store)\n",
    "\n",
    "# Define helper\n",
    "def retrieve_and_generate(query: Annotated[str, \"User query\"]):\n",
    "    q = paraphraser.run(query)\n",
    "    raw = filter_pipeline.run(q)\n",
    "    match = re.search(r\"```json\\n(.*?)\\n```\", raw, re.DOTALL)\n",
    "    filters = json.loads(match.group(1)) if match else {}\n",
    "    return rag_pipeline.run(q, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50d1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_tool = Tool(\n",
    "    name=\"retrieve_and_generate_recommendation\",\n",
    "    description=\"Retrieve product info and recommend items.\",\n",
    "    function=retrieve_and_generate,\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"query\": {\"type\": \"string\"}},\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c077ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    chat_generator=OpenAIChatGenerator(model=\"gpt-4.1\", api_key=Secret.from_token(os.environ[\"OPENAI_API_KEY\"])),\n",
    "    tools=[retrieve_tool],\n",
    "    system_prompt=\"\"\"\n",
    "    You are a helpful SmartShopper assistant. \n",
    "    - If user asks product-related questions → use retrieve_and_generate_recommendation.\n",
    "    - If user asks general info → respond politely.\n",
    "    - Always analyze conversation context first.\n",
    "    \"\"\",\n",
    "    exit_conditions=[\"text\"],\n",
    "    max_agent_steps=10,\n",
    ")\n",
    "agent.warm_up()\n",
    "chat_message_writer = ChatMessageWriter(chat_message_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663fd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.core.pipeline.pipeline -  Running component memory_retriever\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component prompt_builder\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component chat_generator\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component tool_invoker\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component memory_retriever\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component prompt_builder\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component generator\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component categories\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component materials\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component prompt_builder\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component generator\n",
      "INFO - haystack.core.pipeline.base -  Warming up component embedder...\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component embedder\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component retriever\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component prompt_builder\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component generator\n",
      "INFO - haystack.core.pipeline.pipeline -  Running component chat_generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Here are some jackets made of polyester:\n",
      "\n",
      "1. Patagonia Women's Better Sweater Fleece Jacket — $179.48\n",
      "2. Nike Comp 12 Poly Jacket — $64.99\n",
      "3. GM Chevrolet Unisex Bonded All-Season Jacket — $64.99\n",
      "4. Trespass Packup Kids P-Way Jacket — $10.18\n",
      "5. Kryptek Men's Waterproof Dalibor II Jacket, Mandrake — $92.99\n",
      "6. SafetyShirtz SS360 Seattle Safety Hoody ANSI Class 3 — $49.99\n",
      "7. Sport Tek Colorblock Raglan Jacket — $32.02\n",
      "\n",
      "If you'd like more information about any specific jacket, just let me know!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"\\nYou: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    hist = history.run()\n",
    "    messages = [ChatMessage.from_system(hist), ChatMessage.from_user(query)]\n",
    "\n",
    "    chat_message_writer.run([ChatMessage.from_user(query)])\n",
    "    result = agent.run(messages=messages)\n",
    "    reply = result[\"messages\"][-1].text\n",
    "\n",
    "    chat_message_writer.run([ChatMessage.from_assistant(reply)])\n",
    "    print(f\"AI: {reply}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
